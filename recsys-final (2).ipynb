{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":62803,"databundleVersionId":6919098,"sourceType":"competition"},{"sourceId":7140111,"sourceType":"datasetVersion","datasetId":4120905}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!sed -i 's/np\\.int/int/g' /opt/conda/lib/python3.10/site-packages/skopt/space/transformers.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Imposta il percorso della cartella di input\ninput_folder_path = '/kaggle/input/finalrepo/ProgettoReccomender'\n\n# Verifica se la cartella di input esiste\nif os.path.exists(input_folder_path):\n    # Spostati nella cartella di input\n    os.chdir(input_folder_path)\n    \n    # Stampa il nuovo percorso di lavoro\n    print(\"Nuovo percorso di lavoro:\", os.getcwd())\nelse:\n    print(f\"La cartella di input '{input_folder_path}' non esiste.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:39:02.021592Z","iopub.execute_input":"2023-12-29T16:39:02.022838Z","iopub.status.idle":"2023-12-29T16:39:02.033573Z","shell.execute_reply.started":"2023-12-29T16:39:02.022780Z","shell.execute_reply":"2023-12-29T16:39:02.031822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#**ALGORITMO RIASSUNTIVO **\n\nfrom Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\nimport pandas as pd\nimport scipy.sparse as sp\n\n\n#Files path\ntrain_data = \"/kaggle/input/recommender-system-2023-challenge-polimi/data_train.csv\"\nusers_file = \"/kaggle/input/recommender-system-2023-challenge-polimi/data_target_users_test.csv\"\n\n#Files Opening\nURM_file  = open(train_data, 'r')\nusers_to_recommend = open(users_file, 'r')\n\n#Users to reccomend reading\nusers = pd.read_csv(users_to_recommend, names=['user_id'], header=0, dtype={0:int})\n\n#URM Reading\ncolumn_names = ['user_id','item_id','data']\ndataframe = pd.read_csv(URM_file, names=column_names, header=0, dtype={0:int, 1:int, 2:float})\nprint(dataframe.head(20))\n\nURM_all = sp.coo_matrix((dataframe[\"data\"].values, \n                          (dataframe[\"user_id\"].values, dataframe[\"item_id\"].values)))","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:39:02.035570Z","iopub.execute_input":"2023-12-29T16:39:02.035950Z","iopub.status.idle":"2023-12-29T16:39:03.178600Z","shell.execute_reply.started":"2023-12-29T16:39:02.035920Z","shell.execute_reply":"2023-12-29T16:39:03.177322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Evaluation.Evaluator import EvaluatorHoldout\n\nURM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)\nURM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage = 0.8)\n\nevaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\nevaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])\n\n\nfrom skopt.space import Real, Integer, Categorical\nfrom HyperparameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\nfrom Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\nfrom Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\nfrom Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n\n\nrp3_index  = 0\nslim_index = 2\n\nparams_list = [\n    {\"alpha\": 0.3365280890390189, \"beta\": 0.14559541984971103, \"topK\": 32}, #BEST CONFIG BASED ON 30 TESTs\n    {\"alpha\": 0.33543320721534375, \"beta\": 0.13643832833854405, \"topK\": 31},  #Previous best CONFIG\n    {\"alpha\": 0.3227577390094315, \"beta\": 0.12631978308173344, \"topK\": 32},\n    {\"alpha\": 0.2617995480887691, \"beta\": 0.22418804987168886, \"topK\": 30},\n    {'alpha': 0.28585975670634217, 'beta': 0.13388489746818844, 'topK': 33},\n    {'alpha': 0.3361086178381283, 'beta': 0.13949133462799973, 'topK': 29}\n]\n\n\nrecommender_object_RP3 = RP3betaRecommender(URM_train)\nrecommender_object_RP3.fit(alpha=params_list[rp3_index][\"alpha\"], \n                           beta=params_list[rp3_index][\"beta\"], \n                           topK=params_list[rp3_index][\"topK\"], \n                           implicit=True)\n\nslim_params_list = [\n    {'topK': 2305, 'l1_ratio': 0.15984659917724292, 'alpha': 0.0006895792558081994},  # BEST\n    {'topK': 2339, 'l1_ratio': 0.15486907556362542, 'alpha': 0.0006851706335261893},  #previous BEST CONFIG\n    {\"topK\": 2327, \"l1_ratio\": 0.15346747937279875, \"alpha\": 0.000677913689441996}, # New Best\n    {'topK': 2427, 'l1_ratio': 0.14931044947790595, 'alpha': 0.0007442377587336158},\n    {'topK': 2310, 'l1_ratio': 0.1519150334556062, 'alpha': 0.0006862030334431442}\n    \n]\n\nrecommender_object_SLIM = SLIMElasticNetRecommender(URM_train)\nrecommender_object_SLIM.fit(topK= slim_params_list[slim_index][\"topK\"],\n                            l1_ratio= slim_params_list[slim_index][\"l1_ratio\"], \n                            alpha= slim_params_list[slim_index][\"alpha\"])\n\n\nresults_df, results_run_string = evaluator_test.evaluateRecommender(recommender_object_RP3)\nprint(\"RP3 : \", results_run_string)\nresults_df, results_run_string = evaluator_test.evaluateRecommender(recommender_object_SLIM)\nprint(\"SLIM : \", results_run_string)\nprint(\"Now in Validation : \")\nresults_df, results_run_string = evaluator_validation.evaluateRecommender(recommender_object_RP3)\nprint(\"RP3 : \", results_run_string)\nresults_df, results_run_string = evaluator_validation.evaluateRecommender(recommender_object_SLIM)\nprint(\"SLIM : \", results_run_string)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:39:03.182048Z","iopub.execute_input":"2023-12-29T16:39:03.182493Z","iopub.status.idle":"2023-12-29T16:52:10.492786Z","shell.execute_reply.started":"2023-12-29T16:39:03.182453Z","shell.execute_reply":"2023-12-29T16:52:10.490744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testo tutti i parametri per RP3 (occhio che cambio gli splitting di train e validation)\nfrom Evaluation.Evaluator import EvaluatorHoldout\n\nwinning_counts = [0] * 6  # Inizializza una lista per contare quante volte ogni configurazione vince\n\nfor j in range(5):        \n    print(\"ROUND : \", j)\n    URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage=0.8)\n    URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=0.8)\n\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])\n\n    round_winner_index = None\n    max_map = 0.0\n\n    for i in range(6):    \n        recommender_object_RP3 = RP3betaRecommender(URM_train_validation)\n        recommender_object_RP3.fit(alpha=params_list[i][\"alpha\"], \n                                   beta=params_list[i][\"beta\"], \n                                   topK=params_list[i][\"topK\"], \n                                   implicit=True)\n\n        results_df, results_run_string = evaluator_test.evaluateRecommender(recommender_object_RP3)\n        current_map = results_df[\"MAP\"].item()\n\n        print(i, \") RP3 MAP: \", current_map)\n\n        \n        if current_map > max_map:\n            max_map = current_map\n            round_winner_index = i\n\n    # Incrementa il contatore per l'indice della configurazione che vince il round corrente\n    winning_counts[round_winner_index] += 1\n\n# Trova l'indice della configurazione con il maggior numero di vittorie\nwinner_index = winning_counts.index(max(winning_counts))\n\n# Stampa il vincitore finale\nprint(\"\\nWinner Configuration:\")\nprint(f\"Index: {winner_index}, Wins: {winning_counts[winner_index]} rounds\")\n\nrp3_index = 0\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T17:00:10.281900Z","iopub.execute_input":"2023-12-29T17:00:10.282341Z","iopub.status.idle":"2023-12-29T17:07:06.023777Z","shell.execute_reply.started":"2023-12-29T17:00:10.282304Z","shell.execute_reply":"2023-12-29T17:07:06.022172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testo tutti i parametri per SLIM (occhio che cambio gli splitting di train e validation)\nfrom Evaluation.Evaluator import EvaluatorHoldout\n\nwinning_counts = [0] * 5  # Inizializza una lista per contare quante volte ogni configurazione vince\n\nfor j in range(6):        \n    print(\"ROUND : \", j)\n    URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage=0.8)\n    URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=0.8)\n\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])\n\n    round_winner_index = None\n    max_map = 0.0\n\n    for i in range(5):    \n        recommender_object_SLIM = SLIMElasticNetRecommender(URM_train)\n        recommender_object_SLIM.fit(topK= slim_params_list[i][\"topK\"],\n                                l1_ratio= slim_params_list[i][\"l1_ratio\"], \n                                alpha= slim_params_list[i][\"alpha\"])\n    \n        results_df, results_run_string = evaluator_test.evaluateRecommender(recommender_object_SLIM)\n        current_map = results_df[\"MAP\"].item()\n        print(i,\") SLIM MAP: \", current_map)\n        \n        if current_map > max_map:\n            max_map = current_map\n            round_winner_index = i\n\n    # Incrementa il contatore per l'indice della configurazione che vince il round corrente\n    winning_counts[round_winner_index] += 1\n\n# Trova l'indice della configurazione con il maggior numero di vittorie\nwinner_index = winning_counts.index(max(winning_counts))\n\n# Stampa il vincitore finale\nprint(\"\\nWinner Configuration:\")\nprint(f\"Index: {winner_index}, Wins: {winning_counts[winner_index]} rounds\")\n\nslim_index = winner_index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cross Validation\n'''\nfrom Evaluation.Evaluator import EvaluatorHoldout\nfrom Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\nfrom sklearn.model_selection import KFold\n\n# Le tue funzioni di splitting\ndef split_data(URM_all, train_percentage):\n    URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_percentage)\n    URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=train_percentage)\n    return URM_train, URM_validation, URM_test\n\n# Numero di fold per la cross-validation\nnum_folds = 30\nkf = KFold(n_splits=num_folds)\n\n\nbest_map = 0.0\nbest_params = None\n\nfor i, params in enumerate(params_list):\n    map_sum = 0.0\n\n    for train_index, val_index in kf.split(URM_all):\n        URM_train, URM_validation, URM_test = split_data(URM_all, train_percentage=0.8)\n\n        recommender_object_RP3 = RP3betaRecommender(URM_train_validation)\n\n        recommender_object_RP3.fit(alpha=params[\"alpha\"], beta=params[\"beta\"], topK=params[\"topK\"], implicit=True)\n\n        results_df, _ = evaluator_test.evaluateRecommender(recommender_object_RP3)\n        map_value = results_df[\"MAP\"].item()\n        map_sum += map_value\n\n    avg_map = map_sum / num_folds\n\n    print(f\"{i + 1}) RP3 with params {params}: Avg MAP = {avg_map}\")\n\n    if avg_map > best_map:\n        best_map = avg_map\n        best_params = params\n\nprint(f\"Best parameters: {best_params}, Best Avg MAP: {best_map}\")\n'''","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:52:26.621562Z","iopub.status.idle":"2023-12-29T16:52:26.622938Z","shell.execute_reply.started":"2023-12-29T16:52:26.622433Z","shell.execute_reply":"2023-12-29T16:52:26.622481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comprensione del range dei valori di alpha\n\nalpha_values = [0, 0.12, 0.22, 0.32, 0.42, 0.52, 0.62, 0.72, 0.82, 0.92, 1]\n\nbest_alpha = None\nbest_map = 0.0\n\nfor x in alpha_values:\n    new_similarity = (1 - x) * recommender_object_RP3.W_sparse + x * recommender_object_SLIM.W_sparse\n    \n    hybridrecommender_object = ItemKNNCustomSimilarityRecommender(URM_train)\n    hybridrecommender_object.fit(new_similarity)\n    \n    result_df, _ = evaluator_validation.evaluateRecommender(hybridrecommender_object)\n    map_value = result_df[\"MAP\"].values[0]\n    print(\"MAP : \", map_value)\n\n    if map_value > best_map:\n        best_map = map_value\n        best_alpha = x\n\nprint(f\"Miglior valore di alpha in validation: {best_alpha}\")\nprint(f\"Miglior valore di MAP: {best_map}\")\n\n#TEST BEST ALPHA on URM_TRAIN\nimport numpy as np\n'''\ndef run_experiment(alpha):\n    new_similarity = (1 - alpha) * recommender_object_RP3.W_sparse + alpha * recommender_object_SLIM.W_sparse\n\n    hybridrecommender_object = ItemKNNCustomSimilarityRecommender(URM_train)\n    hybridrecommender_object.fit(new_similarity)\n\n    results_df_test, results_run_string_test = evaluator_test.evaluateRecommender(hybridrecommender_object)\n    print(\"alpha : \", alpha, results_run_string_test)\n\n    return results_df_test, alpha\n\n\n# Loop over alpha values\nalpha_values = [round(x, 4) for x in list(np.arange(0.50, 0.63, 0.001))]  # Generates a list of alpha values\n\n# Initialize a list to store the top 5 alphas and their corresponding MAP scores\ntop_alphas = []\n\nfor alpha in alpha_values:\n    results_test, current_alpha = run_experiment(alpha)\n\n    # Update the list of top alphas\n    top_alphas.append((current_alpha, results_test[\"MAP\"].values[0]))\n\n    # Sort the list based on MAP scores in descending order\n    top_alphas = sorted(top_alphas, key=lambda x: x[1], reverse=True)[:5]\n\n# Print the top 5 alphas and their corresponding MAP scores\nprint(\"Top 5 alphas and their MAP scores:\")\nfor i, (alpha, map_score) in enumerate(top_alphas, 1):\n    print(f\"Rank {i}: Alpha = {alpha}, MAP = {map_score}\")\n\n# Extract the best alpha for the test set\nbest_alpha_test = top_alphas[0][0]\n\n# Print the results\nprint(f\"Best alpha for test set: {best_alpha_test}, Best MAP: {top_alphas[0][1]}\")\n\nalpha = best_alpha_test\n'''\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:52:26.625387Z","iopub.status.idle":"2023-12-29T16:52:26.625979Z","shell.execute_reply.started":"2023-12-29T16:52:26.625685Z","shell.execute_reply":"2023-12-29T16:52:26.625719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ORA RITRAINO con URM_TRAIN_VALIDATION (pi√π dati)\n\nrecommender_object_RP3 = RP3betaRecommender(URM_train_validation)\nrecommender_object_RP3.fit(alpha=params_list[rp3_index][\"alpha\"], \n                           beta=params_list[rp3_index][\"beta\"], \n                           topK=params_list[rp3_index][\"topK\"], \n                           implicit=True)\n\nrecommender_object_SLIM = SLIMElasticNetRecommender(URM_train_validation)\nrecommender_object_SLIM.fit(topK= slim_params_list[slim_index][\"topK\"],\n                            l1_ratio= slim_params_list[slim_index][\"l1_ratio\"], \n                            alpha= slim_params_list[slim_index][\"alpha\"])\n\ndef run_experiment2(alpha):\n    new_similarity = (1 - alpha) * recommender_object_RP3.W_sparse + alpha * recommender_object_SLIM.W_sparse\n\n    hybridrecommender_object = ItemKNNCustomSimilarityRecommender(URM_train_validation)\n    hybridrecommender_object.fit(new_similarity)\n\n    results_df_test, results_run_string_test = evaluator_test.evaluateRecommender(hybridrecommender_object)\n    print(\"alpha : \", alpha, \"MAP : \", results_df_test[\"MAP\"].values[0])\n\n    return results_df_test, alpha\n\n\n# Loop over alpha values\nalpha_values = [round(x, 4) for x in list(np.arange(0.45, 0.65, 0.001))]  # Generates a list of alpha values\ntop_alphas = []\n\nfor alpha in alpha_values:\n    results_test, current_alpha = run_experiment2(alpha)\n    top_alphas.append((current_alpha, results_test[\"MAP\"].values[0]))\n\n    # Sort the list based on MAP scores in descending order\n    top_alphas = sorted(top_alphas, key=lambda x: x[1], reverse=True)[:5]\n\n# Print the top 5 alphas and their corresponding MAP scores\nprint(\"Top 5 alphas and their MAP scores:\")\nfor i, (alpha, map_score) in enumerate(top_alphas, 1):\n    print(f\"Rank {i}: Alpha = {alpha}, MAP = {map_score}\")\n\n# Extract the best alpha for the test set\nbest_alpha_test = top_alphas[0][0]\n\n# Print the results\nprint(f\"Best alpha for test set: {best_alpha_test}, Best MAP: {top_alphas[0][1]}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ORA RITRAINO con URM_ALL per fare le predizioni\n\n\nprint (\"Alpha: \", best_alpha_test)\nprint(\"RP3 params: \", params_list[rp3_index])\nprint(\"SLIM params : \", slim_params_list[slim_index])\n\nrecommender_object_RP3 = RP3betaRecommender(URM_all)\nrecommender_object_RP3.fit(alpha=params_list[rp3_index][\"alpha\"], \n                           beta=params_list[rp3_index][\"beta\"], \n                           topK=params_list[rp3_index][\"topK\"], \n                           implicit=True)\n\nrecommender_object_SLIM = SLIMElasticNetRecommender(URM_all)\nrecommender_object_SLIM.fit(topK= slim_params_list[slim_index][\"topK\"],\n                            l1_ratio= slim_params_list[slim_index][\"l1_ratio\"], \n                            alpha= slim_params_list[slim_index][\"alpha\"])\n\n\nnew_similarity = (1 - best_alpha_test) * recommender_object_RP3.W_sparse + best_alpha_test * recommender_object_SLIM.W_sparse\n\n\nhybridrecommender_object = ItemKNNCustomSimilarityRecommender(URM_all)\nhybridrecommender_object.fit(new_similarity)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST\nhybridrecommender_object.recommend(1, cutoff=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport csv\n\nfolder_path = \"/kaggle/working/result_experiments/\"\n\nos.makedirs(folder_path, exist_ok=True)\n\ncsv_filename = os.path.join(folder_path, \"sample_submission.csv\")\n\nif not os.path.isfile(csv_filename):\n    open(csv_filename, 'w').close()\n\nwith open(csv_filename, 'w', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file)\n\n    csv_writer.writerow(['user_id', 'item_list'])\n    for user_id in users['user_id']:\n        item_list_str = ' '.join(map(str, hybridrecommender_object.recommend(user_id, cutoff=10)))\n        # Scrivi nel file l'ID utente originale\n        csv_writer.writerow([user_id, item_list_str])        \n\nprint(f\"CSV file '{csv_filename}' has been created.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-29T16:52:26.627271Z","iopub.status.idle":"2023-12-29T16:52:26.627761Z","shell.execute_reply.started":"2023-12-29T16:52:26.627527Z","shell.execute_reply":"2023-12-29T16:52:26.627548Z"},"trusted":true},"execution_count":null,"outputs":[]}]}